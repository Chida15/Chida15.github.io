<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F28%2Fpackage%2F</url>
    <content type="text"><![CDATA[{"dependencies":{"hexo-generator-archive":"^1.0.0","hexo-generator-category":"^1.0.0","hexo-generator-index":"^1.0.0","hexo-generator-searchdb":"^1.0.8","hexo-generator-tag":"^1.0.0","hexo-renderer-ejs":"^1.0.0","hexo-renderer-marked":"^2.0.0","hexo-renderer-stylus":"^1.1.0","hexo-server":"^1.0.0","hexo-wordcount":"^6.0.1"}}]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何将hexo博客从Ubuntu下迁移至Mac]]></title>
    <url>%2F2019%2F09%2F28%2F%E5%A6%82%E4%BD%95%E5%B0%86hexo%E5%8D%9A%E5%AE%A2%E4%BB%8EUbuntu%E4%B8%8B%E8%BF%81%E7%A7%BB%E8%87%B3Mac%2F</url>
    <content type="text"><![CDATA[1.迁移过程1.1 在Mac下安装git并添加公钥具体内容可以百度搜索，不过多赘述。1.2 下载Node.js此处下载1.3 拷贝原来的文件到新电脑中必须拷贝的文件有：_config.yml，theme/，source/，scaffolds/，package.json，.gitignore不需要拷贝的文件有：.git/，node_modules/，public/，.deploy_git/，db.json1.4 安装hexo在安装过程中，由于npm的镜像在国外，所以遇到了一些错误，后来改用淘宝的cnpm才得以解决，以下是方法：install -g cnpm --registry12 1.5 使用cnpm install命令进行模块安装注意不要使用hexo init1.6 安装deployerinstall hexo-generator-git --save12 2.遇到的问题2.1 插件重复安装在node_modules文件夹河package,json文件夹中删除相应的插件2.2 hexo clean使用出错把public中需要编译的内容（比如CNAME文件）移到source文件夹中，然后进行hexo clean。当执行hexo g的时候会重新创建pulic文件夹，复原其中的文件。2.3 无法部署新的文章到github上####因为我使用了原来文件中的node_modules，可以删除它再cnmp install 参考链接1.https://www.zhihu.com/question/21193762/answer/103097754]]></content>
      <tags>
        <tag>Solutions</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何从零搭建unet网络]]></title>
    <url>%2F2019%2F07%2F09%2F%E5%A6%82%E4%BD%95%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BAunet%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[数据增强123456789101112'''数据增强'''import randomfrom PIL import Imagefrom torchvision import transformsimport torchvision.transforms.functional as tfimport osmask_path = './data/old_mask/'image_path = './data/old_images/'mask_save_path = './data/mask/'image_save_path = './data/images/'num = 100 123456789def RandomFilp(image, mask): '''随机翻转''' if random.random() &gt; 0.5: image = tf.hflip(image) mask = tf.hflip(mask) else: image = tf.vflip(image) mask = tf.vflip(mask) return image, mask 123456def RandomRotation(image, mask): '''随机旋转''' angle = transforms.RandomRotation.get_params([-180, 180]) image = tf.rotate(image, angle, resample=Image.NEAREST) mask = tf.rotate(mask, angle, resample=Image.NEAREST) return image, mask 1234567891011121314def RandomCrop(image, mask): '''随机裁剪''' if random.random() &gt; 0.5: i, j, h, w = transforms.RandomResizedCrop.get_params( image, scale=(0.5, 1.0), ratio = (1,1)) image = tf.resized_crop(image, i, j, h, w, (396, 476)) mask = tf.resized_crop(mask, i, j, h, w, (396, 476)) else: pad = random.randint(0, 192) image = tf.pad(image, pad) image = tf.resize(image, (396, 476)) mask = tf.pad(mask, pad) mask = tf.resize(mask, (396, 476)) return image, mask 1234567891011121314151617181920def transform(image, mask): # 旋转 # angle是-180到180的随机数 angle = transforms.RandomRotation.get_params([-180, 180]) image = tf.rotate(image, angle, resample=Image.NEAREST) mask = tf.rotate(mask, angle, resample=Image.NEAREST) # 随机翻转 if random.random() &gt; 0.5: image, mask = RandomFilp(image, mask) # 随机裁剪 if random.random() &gt; 0.5: image, mask = RandomCrop(image, mask) # 随机旋转 if random.random() &gt; 0.5: image, mask = RandomRotation(image, mask) return image, mask 123456789101112def Augmentation(): '''数据增强''' images_name = os.listdir(image_path) j = 1; for image_name in images_name: for i in range(num): image = Image.open(image_path + image_name) mask = Image.open(mask_path + image_name) new_image, new_mask = transform(image, mask) new_image.save(image_save_path + str(j) + '.png') new_mask.save(mask_save_path + str(j) + '.png') j += 1 12if __name__ == '__main__': Augmentation() Dataloader创建12345678from torch.utils.data import Dataset, DataLoader, random_splitimport torchvision.transforms as transformsimport osimport PIL.Image as Imageimport numpy as npimg_path = './data/images/'msk_path = './data/mask/' 123456transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])target_transform = transforms.ToTensor() 12345678910111213141516171819202122class SpineData(Dataset): def __init__(self, transform=None, target_transform=None): self.transform = transform self.target_transform = target_transform def __len__(self): return len(os.listdir(img_path)) def __getitem__(self, idx): image_name = os.listdir(img_path)[idx] image = Image.open(img_path + image_name).convert('RGB') image = image.resize((256, 256)) # 统一大小可以加快训练速度 mask = Image.open(msk_path + image_name).convert('L') mask = mask.resize((256, 256)) # 将image和mask都转为Tensor格式 if self.target_transform: mask = self.target_transform(mask) if self.transform: image = self.transform(image) return image, mask 123456789101112spine_data = SpineData(transform, target_transform)train_size = int(0.9 * len(spine_data))test_sizee = len(spine_data) - train_sizetrainset, testset = random_split(spine_data, (train_size, test_sizee))trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)testloader = DataLoader(testset)dataiter = iter(trainloader)img, msk = dataiter.next() Unet网络搭建123import torch.nn as nnimport torch.nn.functional as Fimport torch 12345678910111213class DoubleConv(nn.Module): def __init__(self,in_ch,out_ch): super(DoubleConv,self).__init__() self.conv = nn.Sequential( nn.Conv2d(in_ch,out_ch,3,padding=1),# in_ch、out_ch是通道数 nn.BatchNorm2d(out_ch), nn.ReLU(inplace = True), nn.Conv2d(out_ch,out_ch,3,padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace = True) ) def forward(self,x): return self.conv(x) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class UNet(nn.Module): def __init__(self, in_ch, out_ch): super(UNet, self).__init__() super(UNet,self).__init__() self.conv1 = DoubleConv(in_ch,64) self.pool1 = nn.MaxPool2d(2) self.conv2 = DoubleConv(64,128) self.pool2 = nn.MaxPool2d(2) self.conv3 = DoubleConv(128,256) self.pool3 = nn.MaxPool2d(2) self.conv4 = DoubleConv(256,512) self.pool4 = nn.MaxPool2d(2) self.conv5 = DoubleConv(512,1024) #逆卷积 self.up6 = nn.ConvTranspose2d(1024,512,2,stride=2) self.conv6 = DoubleConv(1024,512) self.up7 = nn.ConvTranspose2d(512,256,2,stride=2) self.conv7 = DoubleConv(512,256) self.up8 = nn.ConvTranspose2d(256,128,2,stride=2) self.conv8 = DoubleConv(256,128) self.up9 = nn.ConvTranspose2d(128,64,2,stride=2) self.conv9 = DoubleConv(128,64) self.conv10 = nn.Conv2d(64,out_ch,1) def forward(self, x): c1 = self.conv1(x) p1 = self.pool1(c1) c2 = self.conv2(p1) p2 = self.pool2(c2) c3 = self.conv3(p2) p3 = self.pool3(c3) c4 = self.conv4(p3) p4 = self.pool4(c4) c5 = self.conv5(p4) up_6 = self.up6(c5) merge6 = torch.cat([up_6,c4],dim=1)# 按列拼接 c6 = self.conv6(merge6) up_7 = self.up7(c6) merge7 = torch.cat([up_7,c3],dim=1) c7 = self.conv7(merge7) up_8 = self.up8(c7) merge8 = torch.cat([up_8,c2],dim=1) c8 = self.conv8(merge8) up_9 = self.up9(c8) merge9 = torch.cat([up_9,c1],dim=1) c9 = self.conv9(merge9) c10 = self.conv10(c9) out = nn.Sigmoid()(c10)# 化成(0~1)区间 return out 网络训练与测试123456import torch.optim as optimfrom data_loader import trainloader, testloaderfrom unet import UNetimport torch.nn as nnimport torchimport numpy as np 12device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")model = UNet(3, 1) 1234567891011121314151617181920def train_model(model, criterion, optimizer, num_epochs=2): for epoch in range(num_epochs): print('Epoch &#123;&#125;/&#123;&#125;'.format(epoch, num_epochs - 1)) print('-' * 10) dataset_size = len(trainloader.dataset) epoch_loss = 0 step = 0 #minibatch数 for x, y in trainloader:# 分100次遍历数据集，每次遍历batch_size=4 optimizer.zero_grad()#每次minibatch都要将梯度(dw,db,...)清零 inputs = x labels = y outputs = model(inputs)#前向传播 loss = criterion(outputs, labels)#计算损失 loss.backward()#梯度下降,计算出梯度 optimizer.step()#更新参数一次：所有的优化器Optimizer都实现了step()方法来对所有的参数进行更新 epoch_loss += loss.item() step += 1 print("%d/%d,train_loss:%0.3f" % (step, dataset_size // trainloader.batch_size, loss.item())) print("epoch %d loss:%0.3f" % (epoch, epoch_loss)) 1234def train(): criterion = nn.BCELoss() optimizer = optim.Adam(model.parameters()) train_model(model, criterion, optimizer) 123456789101112131415161718import matplotlib.pyplot as pltdef test(): with torch.no_grad(): for idx, (x, _) in enumerate(testloader): y = model(x) print("y:") print(y) print(y.shape) img_y = torch.squeeze(y).numpy() # 去掉batch_size和channel,这两者均为1 print("img_y:") print(img_y) plt.imshow(img_y) print(img_y.shape) plt.axis('off') plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0) plt.margins(0,0) print("./result/result&#123;&#125;.jpg".format(idx)) plt.savefig("./result/result&#123;&#125;.jpg".format(idx), dpi=100) 12train()test()]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PC端和ipad端如何同步PDF.md]]></title>
    <url>%2F2019%2F04%2F21%2FPC%E7%AB%AF%E5%92%8Cipad%E7%AB%AF%E5%A6%82%E4%BD%95%E5%90%8C%E6%AD%A5PDF%2F</url>
    <content type="text"><![CDATA[使用坚果云和福昕阅读器进行PC端和ipad端的PDF同步1. 在PC端和ipad端同时下载福昕阅读器2. PC端安装坚果云并注册坚果云账号账户信息——&gt;安全选项——&gt;添加应用然后可以得到应用密码，在后面会用到 3. 点击create sync folder设置需要同步的文件夹4. 在ipad端进行设置1.选择cloud点击add选择添加WebDAV2.输入Title，URL(地址是https://dav.jianguoyun.com/dav/),Login(你注册坚果云时候的邮箱)，password（你的坚果云密码），然后save，就可以访问你在PC端设置的同步文件夹了 无论是在PC端还是在ipad端修改PDF后，双方都会立即更新同步信息。]]></content>
      <categories>
        <category>Skills</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何利用github pages打造自己的博客]]></title>
    <url>%2F2019%2F04%2F15%2F%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8github%20pages%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[打造自己的博客（github pages + Hexo + NextT）github创建仓库选择new repositories创建一个仓库，注意仓库的名字是用户名.github.io 安装Hexo1) 安装nodejsm1sudo apt-get install nodejs 2) 安装git1sudo apt-get install git 3) 安装npm1sudo apt-get install npm 4) npm换源(永久换成淘宝源)1npm config set registry https://registry.npm.taobao.org 5) 安装hexo1sudo npm install -g hexo-cli 建站１）创建一个文件夹（作为博客根目录），比如：1mkdir myBlog 2) 初始化博客1npm init myBlog 3) 安装必要依赖12cd myBlognpm install 4) 关联github pages12//在myBlog目录下执行gedit _config.ymｌ 找到deploy,更换成如下内容：1234deploy: type: git repository: git@github.com:用户名/用户名.github.io.git branch: master 换主题：NextT1) 从github上clone NexT1git clone https://github.com/iissnan/hexo-theme-next themes/next //在myBLog目录下执行 2) 更换主题打开myBlog目录下的_config.yml，找到theme: landscape改为theme: next 3) 运行hexo s查看效果 域名绑定1) 申请阿里云域名2) 域名解析在域名界面点击解析，再点击添加记录，分别添加以下两项记录：a)记录类型：CNAME主机记录：@解析线路：默认记录值：用户名.github.ioTTL：10分钟b)记录类型：CNAME主机记录：www解析线路：默认记录值：用户名.github.ioTTL：10分钟 最好使用CNAME，因为ip地址可能会改变。 美化nextT参考博客：http://jeffyang.top/Hexo/Hexo%E4%B8%BB%E9%A2%98Next%E7%BE%8E%E5%8C%96/https://www.jianshu.com/p/f054333ac9e6http://www.yangyong.xyz/2018/01/03/add-hexo-next-post-views/ 阅读次数http://duansm.top/2018/08/03/hexo-next/http://www.yamllint.com/ 检测yaml是否有问题 如何发表与删除文章1) 新建文章1234hexo new a // 生成post，新建并发布文章a，出现在source/_posts中hexo new draft b // 生成draft，新建草稿，出现在source/_drafts中hexo server --draft // 预览草稿hexo publish b // 发布草稿 默认hexo new是生成post，如果要改成其他的（比如draft），可以在myBlog下的_config.yml文件中找到default_layout进行修改，其参数值有：post，draft和page 2）删除文章进入source/_posts文件夹中，找到要删除的md文件，直接本地删除，然后依次执行12hexo ghexo]]></content>
      <categories>
        <category>Installation</category>
      </categories>
      <tags>
        <tag>Blog</tag>
      </tags>
  </entry>
</search>
